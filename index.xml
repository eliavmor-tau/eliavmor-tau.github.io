<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Eliav Mor</title>
    <link>https://eliavmor-tau.github.io/</link>
      <atom:link href="https://eliavmor-tau.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Eliav Mor</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 30 Aug 2021 16:58:34 +0000</lastBuildDate>
    <image>
      <url>https://eliavmor-tau.github.io/media/icon_huc547d0259bdc6e7e33eeb3b2e3b97f0c_12109_512x512_fill_lanczos_center_3.png</url>
      <title>Eliav Mor</title>
      <link>https://eliavmor-tau.github.io/</link>
    </image>
    
    <item>
      <title>Generative Coreference Resolution </title>
      <link>https://eliavmor-tau.github.io/project/generative-coreference-resolution/</link>
      <pubDate>Mon, 30 Aug 2021 16:58:34 +0000</pubDate>
      <guid>https://eliavmor-tau.github.io/project/generative-coreference-resolution/</guid>
      <description>&lt;p&gt;The final project of the course AMNLP (Advanced methods in NLP), together with &lt;a href=&#34;https://www.linkedin.com/in/shimon-malnick-1b8404125/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Shimon Malnick&lt;/a&gt;, we performed an analysis of fine-tuning BART and T5 to solve the CR task on the OntoNotes benchmark. Our best model achieves an average F1 score of 36.8% on CoNLL, while limiting the input length  (due to resource constraints). Our code is publicly available in our github &lt;a href=&#34;https://github.com/ShimonMalnick/Generative-Coreference-Resolution&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Further details can be found in the &lt;a href=&#34;https://drive.google.com/file/d/1UZ4IZqfQ-GxO6Hk_L5fLMc2BouO2079s/view&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;report&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Do Language Models Understand Frequent Words Better?</title>
      <link>https://eliavmor-tau.github.io/project/do-language-models-understand-frequent-words-better/</link>
      <pubDate>Sun, 21 Feb 2021 23:57:28 +0000</pubDate>
      <guid>https://eliavmor-tau.github.io/project/do-language-models-understand-frequent-words-better/</guid>
      <description>&lt;p&gt;Pre-trained language models (LMs) have recently demonstrated outstanding results across a variety of tasks. However, it remains unclear precisely what knowledge the LM manages to capture during pre-training and how word frequency in the training corpus affects the acquisition of knowledge about these words.&lt;/p&gt;
&lt;p&gt;As part of the final project of NLP course I explored the correlation between word occurrence in the language and general world knowledge acquired by a Language Model during pre-training. In my work I propose a framework for testing this subject, using a downstream &amp;ldquo;Yes/No&amp;rdquo; QA task. My findings show positive correlations between: (a) word occurrence and the accuracy of answers for this word. (b) co-occurrence of two words and a tendency of the model to answer &amp;ldquo;Yes&amp;rdquo; for questions about their relation.&lt;/p&gt;
&lt;p&gt;Further details can be found in my &lt;a href=&#34;https://github.com/eliavmor-tau/DoLMUnderstandFrequentWordsBetter&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;github&lt;/a&gt; and &lt;a href=&#34;https://github.com/eliavmor-tau/DoLMUnderstandFrequentWordsBetter/blob/main/Do%20Language%20Models%20Understand%20Frequent%20Word%20Better.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Real-Time Face Detection Using Viola Jonas</title>
      <link>https://eliavmor-tau.github.io/project/face-detection-using-viola-jonas/</link>
      <pubDate>Fri, 19 Jun 2020 15:00:25 +0000</pubDate>
      <guid>https://eliavmor-tau.github.io/project/face-detection-using-viola-jonas/</guid>
      <description>&lt;p&gt;As part of of my passion to CV algorithms, I challenged myself to implement a real-time algorithm for face detection fromÂ &lt;em&gt;scratch&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;For more details please visit my &lt;a href=&#34;https://github.com/eliavmor-tau/ViolaJonesFD/blob/main/README.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Monte-Carlo Snake</title>
      <link>https://eliavmor-tau.github.io/project/montecarlo-snake/</link>
      <pubDate>Thu, 07 May 2020 13:00:00 +0000</pubDate>
      <guid>https://eliavmor-tau.github.io/project/montecarlo-snake/</guid>
      <description>&lt;p&gt;A simple reinforcement learning (snake) game that I wrote for fun while exploring RL during my Master. The learning algorithm of the snake is based on Monte-Carlo using every visit update.&lt;/p&gt;
&lt;p&gt;For more details please visit my &lt;a href=&#34;https://github.com/eliavmor-tau/SnakeGame&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;github&lt;/a&gt; and clone the code!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://eliavmor-tau.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://eliavmor-tau.github.io/about/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://eliavmor-tau.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://eliavmor-tau.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
