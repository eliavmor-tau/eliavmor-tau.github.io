<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Eliav Mor</title>
    <link>https://eliavmor-tau.github.io/project/</link>
      <atom:link href="https://eliavmor-tau.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 30 Aug 2021 16:58:34 +0000</lastBuildDate>
    <image>
      <url>https://eliavmor-tau.github.io/media/icon_huc547d0259bdc6e7e33eeb3b2e3b97f0c_12109_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://eliavmor-tau.github.io/project/</link>
    </image>
    
    <item>
      <title>Generative Coreference Resolution </title>
      <link>https://eliavmor-tau.github.io/project/generative-coreference-resolution/</link>
      <pubDate>Mon, 30 Aug 2021 16:58:34 +0000</pubDate>
      <guid>https://eliavmor-tau.github.io/project/generative-coreference-resolution/</guid>
      <description>&lt;p&gt;The final project of the course AMNLP (Advanced methods in NLP).  &lt;a href=&#34;https://www.linkedin.com/in/shimon-malnick-1b8404125/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Shimon Malnick&lt;/a&gt; and I tried to solve the CR resolution task on the OntoNotes benchmark by fine-tuning BART and T5. Our best model achieved an average F1 score of 36.8% on CoNLL, while limiting the input length (due to resource constraints). Our analysis provides a&lt;/p&gt;
&lt;p&gt;More details and code can be found in our Github &lt;a href=&#34;https://github.com/ShimonMalnick/Generative-Coreference-Resolution&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;repository&lt;/a&gt; and &lt;a href=&#34;https://drive.google.com/file/d/1UZ4IZqfQ-GxO6Hk_L5fLMc2BouO2079s/view&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;report&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Do Language Models Understand Frequent Words Better?</title>
      <link>https://eliavmor-tau.github.io/project/do-language-models-understand-frequent-words-better/</link>
      <pubDate>Sun, 21 Feb 2021 23:57:28 +0000</pubDate>
      <guid>https://eliavmor-tau.github.io/project/do-language-models-understand-frequent-words-better/</guid>
      <description>&lt;p&gt;Pre-trained language models (LMs) have recently demonstrated outstanding results across a variety of tasks. However, it remains unclear precisely what knowledge the LM manages to capture during pre-training and how word frequency in the training corpus affects the acquisition of knowledge about these words.&lt;/p&gt;
&lt;p&gt;As part of the final project of NLP course I explored the correlation between word occurrence in the language and general world knowledge acquired by a Language Model during pre-training. In my work I propose a framework for testing this subject, using a downstream &amp;ldquo;Yes/No&amp;rdquo; QA task. My findings show positive correlations between: (a) word occurrence and the accuracy of answers for this word. (b) co-occurrence of two words and a tendency of the model to answer &amp;ldquo;Yes&amp;rdquo; for questions about their relation.&lt;/p&gt;
&lt;p&gt;Further details can be found in my &lt;a href=&#34;https://github.com/eliavmor-tau/DoLMUnderstandFrequentWordsBetter&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;github&lt;/a&gt; and &lt;a href=&#34;https://github.com/eliavmor-tau/DoLMUnderstandFrequentWordsBetter/blob/main/Do%20Language%20Models%20Understand%20Frequent%20Word%20Better.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Real-Time Face Detection Using Viola Jonas</title>
      <link>https://eliavmor-tau.github.io/project/face-detection-using-viola-jonas/</link>
      <pubDate>Fri, 19 Jun 2020 15:00:25 +0000</pubDate>
      <guid>https://eliavmor-tau.github.io/project/face-detection-using-viola-jonas/</guid>
      <description>&lt;p&gt;As part of of my passion for CV algorithms, I challenged myself to implement a real-time algorithm for face detection from &lt;em&gt;scratch&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The Viola Jones is a very light-weight FD algorithm that combines a set of weak (and fast) classifiers into a single strong classifier using boosting.&lt;/p&gt;
&lt;p&gt;More details, demo and code are available in my &lt;a href=&#34;https://github.com/eliavmor-tau/ViolaJonesFD/blob/main/README.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt; repository.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Monte-Carlo Snake</title>
      <link>https://eliavmor-tau.github.io/project/montecarlo-snake/</link>
      <pubDate>Thu, 07 May 2020 13:00:00 +0000</pubDate>
      <guid>https://eliavmor-tau.github.io/project/montecarlo-snake/</guid>
      <description>&lt;p&gt;A simple reinforcement learning (snake) game that I wrote for fun while exploring RL during my Masters. The learning algorithm of the snake is based on Monte-Carlo using every visit update. More details can be found in the code!&lt;/p&gt;
&lt;p&gt;The project is composed of two main scripts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;scripts/snake.py - Contains the snake logic (Monte-carlo, Q-learning, train/test loop). In order to train and test your algorithm please change the relevant parameters under the &lt;strong&gt;main&lt;/strong&gt; section.&lt;/li&gt;
&lt;li&gt;scripts/SnakeGame.py - The actual snake game - (based on OpenAI Gym API &lt;a href=&#34;https://gym.openai.com/envs/#classic_control&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://gym.openai.com/envs/#classic_control&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Feel free to add you own algorithm and test it using the SnakeGame class in SnakeGame.py!&lt;/p&gt;
&lt;p&gt;Enjoy!&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/eliavmor-tau/SnakeGame&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub repository&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
